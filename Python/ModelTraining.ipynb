{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "108b6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f62903",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03244842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"IMDBDataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998d278",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "399d82a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c3/zx3_nj2x5hvbt8bj7fjh33th0000gn/T/ipykernel_21525/3936166133.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  parse_obj=BeautifulSoup(text,'html.parser')\n"
     ]
    }
   ],
   "source": [
    "#This function will create a parse tree and extract the plain text from a given html text\n",
    "#Eg \"<h1>Hello how are you</h1>  <div class=\\\"Main\\\">Ramesh</div>\" will give\n",
    "# Hello how are you Ramesh\n",
    "def strip_html(text):\n",
    "    parse_obj=BeautifulSoup(text,'html.parser')\n",
    "    return parse_obj.get_text()\n",
    "\n",
    "#re.sub() function to replace occurrences of the specified regular expression pattern with an empty string \n",
    "def remove_square_bracket(text):\n",
    "    text = re.sub(r'\\[[^]]*\\]', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_special_char(text,remove_digits=True):\n",
    "    text=re.sub(r'[^a-zA-Z0-9\\s]','',text)\n",
    "    return text\n",
    "\n",
    "def clean_data(text):\n",
    "    text=strip_html(text)\n",
    "    text=remove_square_bracket(text)\n",
    "    text=remove_special_char(text)\n",
    "    return text\n",
    "\n",
    "df['review']=df['review'].apply(clean_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67770813",
   "metadata": {},
   "source": [
    "## Text Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2db7b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming is done not lemmetisation because stemming work good in information retrival\n",
    "def porter_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text=' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "df['review']=df['review'].apply(porter_stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e664f",
   "metadata": {},
   "source": [
    "## Removing Stop Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21060fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list=set(stopwords.words('english'))\n",
    "tokenizer=ToktokTokenizer()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens=tokenizer.tokenize(text)\n",
    "    tokens=[token.strip() for token in tokens] #strip will remove leading and trailing whitespaces\n",
    "    new_token=[token for token in tokens if token.lower() not in stopwords_list]\n",
    "    new_text=' '.join(new_token)\n",
    "    return new_text\n",
    "\n",
    "df['review']=df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc3e8c",
   "metadata": {},
   "source": [
    "## Labelling Sentimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a40bfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review ha mention watch 1 oz episod youll ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu veri unassu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought thi wa wonder way spend time hot summe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi hi clo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one review ha mention watch 1 oz episod youll ...          1\n",
       "1  wonder littl product film techniqu veri unassu...          1\n",
       "2  thought thi wa wonder way spend time hot summe...          1\n",
       "3  basic famili littl boy jake think zombi hi clo...          0\n",
       "4  petter mattei love time money visual stun film...          1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb=LabelBinarizer()\n",
    "df['sentiment']=lb.fit_transform(df['sentiment'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7fc4ba",
   "metadata": {},
   "source": [
    "## Spliting test train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afd7912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=df.review\n",
    "sentiments=df.sentiment\n",
    "\n",
    "train_review,test_review,train_sentiment,test_sentiment=train_test_split(reviews,sentiments,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ce875",
   "metadata": {},
   "source": [
    "## Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31be9a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_obj=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "tf_train_reviews=tfidf_obj.fit_transform(train_review)\n",
    "tf_test_reviews=tfidf_obj.transform(test_review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0619dce",
   "metadata": {},
   "source": [
    "## MultiNomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dada3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "MNB=MultinomialNB()\n",
    "#MNB_bow=MNB.fit(cv_train_)\n",
    "MNB_model=MNB.fit(tf_train_reviews,train_sentiment)\n",
    "print(MNB_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c00c0a",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "108319f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=MNB.predict(tf_test_reviews)\n",
    "accuracy=accuracy_score(test_sentiment,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ae39bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7424\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
